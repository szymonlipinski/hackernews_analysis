submit()
data_url = "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
main_path <- getwd()
download.file(data_url, file.path(main_path, "dataFiles.zip"))
unzip(zipfile = "dataFiles.zip")
# Load activity_labels.txt and features.txt
activityLabels <- fread(file.path(main_path, "UCI HAR Dataset/activity_labels.txt"), col.names = c("activityClass", "activityName"))
features <- fread(file.path(main_path, "UCI HAR Dataset/features.txt"), col.names = c("featureLabel", "featureName"))
# We want to have only the mean and the standard deviation.
requiredFeatures <- grep("(mean|std)\\(\\)", features$featureName)
requiredFeaturesLabels <- gsub("[()]", "", features[requiredFeatures, ]$featureName)
measurments = features[requiredFeatures, ]
# load test files
testSet <- fread(file.path(main_path, "UCI HAR Dataset/test/X_test.txt"))[, requiredFeatures, with = FALSE]
testLabels <- fread(file.path(main_path, "UCI HAR Dataset/test/y_test.txt"), col.names = c("Label"))
testSubjects <- fread(file.path(main_path, "UCI HAR Dataset/test/subject_test.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(testSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
test <- cbind(testLabels, testSubjects, testSet)
# load train files
trainSet <- fread(file.path(main_path, "UCI HAR Dataset/train/X_train.txt"))[, requiredFeatures, with = FALSE]
trainLabels <- fread(file.path(main_path, "UCI HAR Dataset/train/y_train.txt"), col.names = c("Label"))
trainSubjects <- fread(file.path(main_path, "UCI HAR Dataset/train/subject_train.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(trainSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
train <- cbind(trainLabels, trainSubjects, trainSet)
data <- rbind(test, train)
View(data)
activityLabels
# load test files
testSet <- fread(file.path(main_path, "UCI HAR Dataset/test/X_test.txt"))[, requiredFeatures, with = FALSE]
testLabels <- fread(file.path(main_path, "UCI HAR Dataset/test/y_test.txt"), col.names = c("ActivityLabel"))
testSubjects <- fread(file.path(main_path, "UCI HAR Dataset/test/subject_test.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(testSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
test <- cbind(testLabels, testSubjects, testSet)
# load train files
trainSet <- fread(file.path(main_path, "UCI HAR Dataset/train/X_train.txt"))[, requiredFeatures, with = FALSE]
trainLabels <- fread(file.path(main_path, "UCI HAR Dataset/train/y_train.txt"), col.names = c("ActivityLabel"))
trainSubjects <- fread(file.path(main_path, "UCI HAR Dataset/train/subject_train.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(trainSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
train <- cbind(trainLabels, trainSubjects, trainSet)
data <- rbind(test, train)
?factor
data[, Activity]
data[, ActivityLabel]
factor(data[, ActivityLabel], levels=activityLabels$activityClass, labels=activityLabels$activityName)
data[, ActivityLabel] <- factor(data[, ActivityLabel], levels=activityLabels$activityClass, labels=activityLabels$activityName)
# Load activity_labels.txt and features.txt
activityLabels <- fread(file.path(main_path, "UCI HAR Dataset/activity_labels.txt"), col.names = c("activityClass", "activityName"))
features <- fread(file.path(main_path, "UCI HAR Dataset/features.txt"), col.names = c("featureLabel", "featureName"))
# We want to have only the mean and the standard deviation.
requiredFeatures <- grep("(mean|std)\\(\\)", features$featureName)
requiredFeaturesLabels <- gsub("[()]", "", features[requiredFeatures, ]$featureName)
measurments = features[requiredFeatures, ]
# load test files
testSet <- fread(file.path(main_path, "UCI HAR Dataset/test/X_test.txt"))[, requiredFeatures, with = FALSE]
testLabels <- fread(file.path(main_path, "UCI HAR Dataset/test/y_test.txt"), col.names = c("Activity"))
testSubjects <- fread(file.path(main_path, "UCI HAR Dataset/test/subject_test.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(testSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
test <- cbind(testLabels, testSubjects, testSet)
# load train files
trainSet <- fread(file.path(main_path, "UCI HAR Dataset/train/X_train.txt"))[, requiredFeatures, with = FALSE]
trainLabels <- fread(file.path(main_path, "UCI HAR Dataset/train/y_train.txt"), col.names = c("Activity"))
trainSubjects <- fread(file.path(main_path, "UCI HAR Dataset/train/subject_train.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(trainSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
train <- cbind(trainLabels, trainSubjects, trainSet)
data <- rbind(test, train)
data[, Activity] <- factor(data[, Activity], levels=activityLabels$activityClass, labels=activityLabels$activityName)
factor(data[, Activity], levels=activityLabels$activityClass, labels=activityLabels$activityName)
data$Activity <- factor(data[, Activity], levels=activityLabels$activityClass, labels=activityLabels$activityName)
stats <- data
stats
View(stats)
melt(stats, id=c("Activity", "SubjectNumber"))
a <- melt(stats, id=c("Activity", "SubjectNumber"))
View(a)
?dcast
dcast(a, Activity + SubjectNumber ~ value, fun=mean)
dcast(a, Activity + SubjectNumber ~ variable, fun=mean)
b <- dcast(a, Activity + SubjectNumber ~ variable, fun=mean)
View(b)
?fwrite
# Translate the activity classes to activity names.
data$Activity <- factor(data[, Activity], levels=activityLabels$activityClass, labels=activityLabels$activityName)
tidyData <- melt(stats, id=c("Activity", "SubjectNumber"))
tidyData <- dcast(tidyData, Activity + SubjectNumber ~ variable, fun = mean)
View(tidyData)
?sort
fwrite(x = tidyData, file = "tidyData.txt", quote = FALSE)
fwrite(x = tidyData, file = file.path(main_path, "tidyData.txt"), quote = FALSE)
getwd()
setwd("../..")
getwd()
setwd("../course3/final")
getwd()
data_url = "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
main_path <- getwd()
download.file(data_url, file.path(main_path, "dataFiles.zip"))
unzip(zipfile = "dataFiles.zip")
# Load activity_labels.txt and features.txt
activityLabels <- fread(file.path(main_path, "UCI HAR Dataset/activity_labels.txt"), col.names = c("activityClass", "activityName"))
features <- fread(file.path(main_path, "UCI HAR Dataset/features.txt"), col.names = c("featureLabel", "featureName"))
# We want to have only the mean and the standard deviation.
requiredFeatures <- grep("(mean|std)\\(\\)", features$featureName)
requiredFeaturesLabels <- gsub("[()]", "", features[requiredFeatures, ]$featureName)
measurments = features[requiredFeatures, ]
# load test files
testSet <- fread(file.path(main_path, "UCI HAR Dataset/test/X_test.txt"))[, requiredFeatures, with = FALSE]
testLabels <- fread(file.path(main_path, "UCI HAR Dataset/test/y_test.txt"), col.names = c("Activity"))
testSubjects <- fread(file.path(main_path, "UCI HAR Dataset/test/subject_test.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(testSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
test <- cbind(testLabels, testSubjects, testSet)
# load train files
trainSet <- fread(file.path(main_path, "UCI HAR Dataset/train/X_train.txt"))[, requiredFeatures, with = FALSE]
trainLabels <- fread(file.path(main_path, "UCI HAR Dataset/train/y_train.txt"), col.names = c("Activity"))
trainSubjects <- fread(file.path(main_path, "UCI HAR Dataset/train/subject_train.txt"), col.names = c("SubjectNumber"))
# rename the columns so we use modified labels
names(trainSet) <- requiredFeaturesLabels
# make a nice table with all the columns joined
train <- cbind(trainLabels, trainSubjects, trainSet)
data <- rbind(test, train)
# Translate the activity classes to activity names.
data$Activity <- factor(data[, Activity], levels=activityLabels$activityClass, labels=activityLabels$activityName)
tidyData <- melt(stats, id=c("Activity", "SubjectNumber"))
tidyData <- dcast(tidyData, Activity + SubjectNumber ~ variable, fun = mean)
tidyData <i
fwrite(x = tidyData, file = file.path(main_path, "tidyData.txt"), quote = FALSE)
fwrite(x = tidyData, file = file.path(main_path, "tidyData.csv"), quote = FALSE)
?fwrite
fwrite(tidyData, file = file.path(main_path, "tidyData.csv"), quote = FALSE)
data %>%
melt(id=c("Activity", "SubjectNumber")) %>%
dcast(Activity + SubjectNumber ~ variable, fun = mean) %>%
fwrite(file = file.path(main_path, "tidyData.csv"), quote = FALSE)
source('~/Documents/projects/szymon/data/course3/final/run_analysis.R')
source('~/Documents/projects/szymon/data/course3/final/run_analysis.R')
source('~/Documents/projects/szymon/data/course3/final/run_analysis.R')
rm(list=setdiff(ls(), "x"))
x
rm(list=setdiff(ls()))
ls()
rm(list=ls())
swirl()
dice_sqr
dice_sqr*PDF
dice_sqr*dice_fair
ex2_fair <- sum(dice_sqr*dice_fair)
ex2_fair^2
ex2_fair - 3.5^2
quit()
swirl()
library(swirl)
swirl()
info()
bye()
rm(list=ls())
lambda=0.2
dev=1/lambda
mean=1/lambda
rexp(n, lambda)
rexp(1, lambda)
rexp(2, lambda)
?rexp
rexp(40, lambda)
rexp(40, lambda)
rexp(40, lambda)
rexp(40, lambda)
hist(rexp(40, lambda))
hist(rexp(40, lambda))
hist(rexp(40, lambda))
hist(rexp(40, lambda))
hist(rexp(40, lambda))
hist(rexp(40, lambda))
hist(rexp(40, lambda))
hist(rexp(40, lambda))
rexp(40, lambda)
d <- rexp(100*100, lambda)
d
hist(d)
hist(d)
d <- rexp(1000*1000, lambda)
hist(d)
hist(d)
?runif
hist(runif(1000))
hist(runif(1000*1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(runif(40)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(runif(40)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mean
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
mns = NULL
for (i in 1 : 1000*1000) mns = c(mns, mean(rexp(40, lambda)))
hist(mns)
setwd("~/projects/szymon/datasciencecoursera/statisticalinference")
?replicate
data
lambda
data
replicate(n_simulations, rexp(n, lambda))
lambda <- 0.2
n= 40
n_simulations=100
replicate(n_simulations, rexp(n, lambda))
data <- replicate(n_simulations, rexp(n, lambda))
hist(data)
lambda
n
n_simulations=1000
data <- replicate(n_simulations, rexp(n, lambda))
hist(data)
dim(data)
means <- mean(data)
hist(means)
means <- apply(data, 2, mean)
hist(means)
install.packages('knitr')
install.packages("plotly")
index
========================================================
author: Szymon LipiÅ„ski
date: September 9, 2019
autosize: true
install.packages("webshot")
library(plotly)
plot_ly(mtcars, x=mtcars$wt, y=mtcars$mpg, mode="markers")
install.packages("ggplot2")
install.packages("DBI")
install.packages('rpostgresql')
install.packages('RPostgreSQL')
RPostgreSQL?
;
RPostgreSQL
?RPostgreSQL
??RPostgreSQL
library(odbc)
install.packages('odbc')
library(odbc)
library(odbc)
install.packages('odbc')
library(odbc)
sort(unique(odbcListDrivers()[[1]]))
drv <- dbDriver("PostgreSQL")
library(RPostgreSQL)
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, dbname = "hn",
host = "localhost", port = 5432,
user = "hn", password = hn)
con <- dbConnect(drv, dbname = "hn",
host = "localhost", port = 5432,
user = "hn", password = 'hn')
con <- dbConnect(drv, dbname = "hn",
host = "localhost", port = 5432,
user = "hn", password = "hn")
df_postgres <- dbGetQuery(con, "SELECT * from pg_table")
df_postgres <- dbGetQuery(con, "SELECT * from pg_tables")
df_postgres
df_postgres <- dbGetQuery(con, "select count(*), type, year from raw_data join dates using (object_id) group by year, type;")
df <- dbGetQuery(con, "select count(*), type, year from raw_data join dates using (object_id) group by year, type;")
plot(df)
boxplot(df)
summary(df)
boxplot(type~year, data=df)
df$type <- as.factor(df$type)
boxplot(type~year, data=df)
df$type <- as.factor(df$type)
df$year <- as.factor(df$year)
boxplot(type~year, data=df)
boxplot(type, data=df)
boxplot(type~year, data=df)
boxplot(year~type, data=df)
df
boxplot(year~type, data=df)
df$year <- as.integer(df$year)
boxplot(year~type, data=df)
df <- dbGetQuery(con, "select type, year from raw_data join dates using (object_id);")
boxplot(year~type, data=df)
setwd("~/projects/szymon/data/hnanalysis/rmarkdown")
unlink('~/projects/szymon/data/hnanalysis/rmarkdown/hnanalysis_cache', recursive = TRUE)
?dbGetQuery
unlink('~/projects/szymon/data/hnanalysis/rmarkdown/hnanalysis_cache', recursive = TRUE)
?dbGetQuery
require("RPostgreSQL")
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, dbname = "hn",
host = "localhost", port = 5432,
user = "hn", password = "hn")
getDomainData <- function(con, domain) {
dbGetQuery(con, "
SELECT domain_without_www path, sum(coalesce(points, 0)) point
FROM urls
JOIN data USING (object_id)
WHERE (path IS NOT NULL AND path <> '/')
AND domain_without_www = ?
GROUP BY path
ORDER BY point DESC
LIMIT 20;
", param = domain)
}
getDomainData('amazon.com')
getDomainData <- function(con, domain) {
dbGetQuery(con, "
SELECT domain_without_www path, sum(coalesce(points, 0)) point
FROM urls
JOIN data USING (object_id)
WHERE (path IS NOT NULL AND path <> '/')
AND domain_without_www = ?
GROUP BY path
ORDER BY point DESC
LIMIT 20;
", param = c(domain))
}
getDomainData('amazon.com')
getDomainData(con, 'amazon.com')
getDomainData <- function(con, domain) {
dbGetQuery(con, "
SELECT path, sum(coalesce(points, 0)) point
FROM urls
JOIN data USING (object_id)
WHERE (path IS NOT NULL AND path <> '/')
AND domain_without_www = ?
GROUP BY path
ORDER BY point DESC
LIMIT 20;
", param = domain)
}
getDomainData(con, 'amazon.com')
urls <- dbGetQuery(con, "
WITH distinct_urls AS (
SELECT DISTINCT object_id, protocol, url
FROM urls
UNION
SELECT DISTINCT object_id, 'all',
domain || '/' || path as url
FROM urls
)
SELECT protocol, year_month date, count(*)
FROM distinct_urls
JOIN dates USING (object_id)
WHERE date < date_trunc('month', now())
GROUP BY protocol, year_month
ORDER BY year_month desc, protocol
")
dateRange <- dbGetQuery(con, "SELECT min(year) min, max(year) max FROM dates")
library(ggplot2)
breaks <- mapply({function(year) sprintf("%s-01", year)},
seq(dateRange$min[1], dateRange$max[1]))
ggplot(data = urls, aes(x = date, y = count)) +
geom_point(aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count)) +
geom_point(aes(color = protocol)) +
# geom_smooth(method = "lm", se = FALSE) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
# geom_smooth(method = "lm", se = FALSE) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth() +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = "lm", se = FALSE, aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = "lm", aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = "lm", se = FALSE, aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth( se = FALSE, aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = lm, se = FALSE, aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = "auto", se = FALSE, aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = "y ~ poly(x, 3)", se = FALSE, aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(data = urls, aes(x = date, y = count, group = protocol)) +
geom_point(aes(color = protocol)) +
geom_smooth(method = "loess", se = FALSE, aes(color = protocol)) +
labs(title = "Protocol Distribution For URLs By Month",
x = "Date",
y = "Count",
color = "Entry Type") +
scale_x_discrete(breaks = breaks) +
theme(axis.text.x = element_text(angle = 30, hjust = 1))
unlink('~/projects/szymon/data/hnanalysis/rmarkdown/hnanalysis_cache', recursive = TRUE)
unlink('~/projects/szymon/data/hnanalysis/rmarkdown/hnanalysis_cache', recursive = TRUE)
